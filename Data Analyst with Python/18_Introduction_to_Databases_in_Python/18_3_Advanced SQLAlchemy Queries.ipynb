{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22fa8a3-a853-4dc3-80f6-319dc067a2f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Advanced SQLAlchemy Queries\n",
    "**In this chapter, you will learn to perform advanced—and incredibly useful—queries that enable you to interact with your data in powerful ways.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ff515-6080-4913-8649-6d110098d095",
   "metadata": {},
   "source": [
    "## Calculating values in a query\n",
    "### Math operators\n",
    "Now that you know how to customize your SQL queries using filtering and aggregation functions, it's time to dive deeper by performing typical and useful math operations such as addition(`+`), subtraction(`-`), multiplication(`*`), division(`/`), and modulus(`%`) on columns in our query. It is import to remember that these operations perform differently with non-numeric data types.\n",
    "\n",
    "### Calculating difference\n",
    "If we wanted to find the top five age groups by growth between 2000 and 2008, we would start by passing select the `age` column and then the calculated difference between `pop2008` and `pop2000` columns. Notice that we wrapped the difference in parenthesis so we can apply the label `pop_change` to it. Next we're going to group by age and order by the `pop_change` in descending manner and finally we apply a limit statement to only return the top 5 results. Now we can execute that statement and print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7764c3e5-254f-47fd-b060-afbe1b6090bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Table, MetaData, select, desc\n",
    "engine = create_engine('sqlite:///census.sqlite')\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8077b1d7-9e68-41e4-9e90-c6bfd5929fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(61, 25201), (54, 23503), (55, 21716), (60, 19677), (58, 19526)]\n"
     ]
    }
   ],
   "source": [
    "stmt = select([census.columns.age,\n",
    "              (census.columns.pop2008 - \n",
    "               census.columns.pop2000).label('pop_change')\n",
    "              ])\n",
    "stmt = stmt.group_by(census.columns.age)\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "stmt = stmt.limit(5)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc3201-7e92-413a-a2a0-b1914ec83e9d",
   "metadata": {},
   "source": [
    "That let's us see that the number of 61 and 85 year olds grew quite a bit between those years.\n",
    "\n",
    "### Case statement\n",
    "Often when we are performing calculations, we want to selectively include data in a calculation based on a set of conditions. The case statement allows us to do just that. The case statement has a list of conditions and a column to return if the condition is meet, and it ends with an else that tells it how to handle those rows without a match.\n",
    "\n",
    "### Case example\n",
    "Let's take a look at how a case statement works. Before we begin to look at this example, this is just to demonstrate how case works, we could get the same result where a much simpler select statement and a where clause. However, we'll be building on the case statement in the next example to build queries that a where clause cannot perform. We start by importing the case statement from sqlalchemy. Then we build a select statement that include a `sum` function for a case statement. The case statement begins with a conditional that checks to see if the `state` is `New York`, and if that is the case it returns the value of the `pop2008` column. Next we have an else clause that returns 0 for any record that does not have the state of New York. Then we execute the statement and print the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5106c8f-e18b-47b6-b37b-d59de01dcf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(19465159,)]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func, case\n",
    "stmt = select([\n",
    "        func.sum(\n",
    "            case([\n",
    "                (census.columns.state == 'New York',\n",
    "                census.columns.pop2008)\n",
    "            ], else_=0))])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c256f5-014b-49d3-b2e8-18a6870aa82c",
   "metadata": {},
   "source": [
    "### Cast statement\n",
    "The cast statement is also useful when we are performing operations and you need to convert a column from one type to another. This is useful for converting integers to floats so we get the expected result when we use it in division. It can also be used to convert strings to dates. The case statement accepts a column or expression and the type to which you want to convert it. Let's combine the case and cast statements in an example.\n",
    "\n",
    "### Percentage example\n",
    "If we wanted to find what percentage of the total population live in New York. We start by importing case, cast and float. Then we build a select statement where we are selecting a very complex clause. To calculate a percentage, we need sum the 2008 population for all the rows where the state is New York and dividing it by the sum of the total 2008 population and multiple by 100. We do that by calculating the sum of a case statement that returns the `pop2008` column if the state is New York and 0 for any other record just like our last example. Then we divide that by the sum of the pop2008 column for all the records. However, we are casting that to a Float so we will get a fractional result when we perform the division. This is important because if we don't covert it, it will perform floor or integer division and we'll get 0 back. Next we multiply that by 100 to get the percentage and label the entire calculation as `ny_percent`. Next, we can execute that statement and print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a6b259-2302-42a4-a58b-6b38791723f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6.426761976501632,)]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import case, cast, Float\n",
    "stmt = select([\n",
    "        (func.sum(\n",
    "            case([\n",
    "                (census.columns.state == 'New York',\n",
    "                census.columns.pop2008)\n",
    "            ], else_=0)) /\n",
    "         cast(func.sum(census.columns.pop2008),\n",
    "             Float) * 100).label('ny_percent')])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0b96e-243c-4fb1-bef2-3096dceca464",
   "metadata": {},
   "source": [
    "Notice that we have used a sophisticated SQL query to extract the solution to a very intuitive question from our database: What percentage of the total population lived in New York in 2008?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7455285-0afb-463c-9131-1592a6bcc36e",
   "metadata": {},
   "source": [
    "```\n",
    "6.43%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5c9c6-be33-4222-a50a-b5f5c591d909",
   "metadata": {},
   "source": [
    "## Connecting to a MySQL database\n",
    "Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that in the last chapter you connected to a PostgreSQL database. Now, you'll connect to a MySQL database, for which many prefer to use the `pymysql` database driver, which, like `psycopg2` for PostgreSQL, you have to install prior to use.\n",
    "\n",
    "This connection string is going to start with `'mysql+pymysql://'`, indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the `'username:password'` combo. Next, you specify the host and port with the following `'@host:port/'`. Finally, you wrap up the connection string with the `'database_name'`.\n",
    "\n",
    "Now you'll practice connecting to a MySQL database: it will be the same `census` database that you have already been working with. One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276d4b1-7f5b-4fb0-86c5-a75c4ca4f5e8",
   "metadata": {},
   "source": [
    "- Import the `create_engine` function from the `sqlalchemy` library.\n",
    "- Create an engine to the `census` database by concatenating the following strings and passing them to `create_engine()`:\n",
    "    - `'mysql+pymysql://'` (the dialect and driver).\n",
    "    - `'student:datacamp'` (the username and password).\n",
    "    - `'@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/'` (the host and port).\n",
    "    - `'census'` (the database name).\n",
    "- Use the `.table_names()` method on `engine` to print the table names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf93adc-469b-4ee2-be6d-6e0719efe172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMySQL in c:\\users\\sj501\\anaconda3\\lib\\site-packages (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec0bcc8-0268-486d-b10b-973f1e03a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census', 'state_fact']\n"
     ]
    }
   ],
   "source": [
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('mysql+pymysql://student:datacamp@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/census')\n",
    "\n",
    "# Print the table names\n",
    "print(engine.table_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30afba-2704-42e2-acdf-ceb874a9c00b",
   "metadata": {},
   "source": [
    "## Calculating a difference between two columns\n",
    "Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python.\n",
    "\n",
    "You can use these operators to perform addition (`+`), subtraction (`-`), multiplication (`*`), division (`/`), and modulus (`%`) operations. Note: They behave differently when used with non-numeric column types.\n",
    "\n",
    "Let's now find the top 5 states by population growth between 2000 and 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348677f7-b8ec-4174-b7b9-047d29f5db1b",
   "metadata": {},
   "source": [
    "- Define a select statement called `stmt` to return:\n",
    "     1. The state column of the `census` table (`census.columns.state`).\n",
    "    2. The difference in population count between 2008 (`census.columns.pop2008`) and 2000 (`census.columns.pop2000`) labeled as `'pop_change'`.\n",
    "- Group the statement by `census.columns.state`.\n",
    "- Order the statement by population change (`'pop_change'`) in descending order. Do so by passing it desc(`'pop_change'`).\n",
    "- Use the `.limit()` method on the previous statement to return only 5 records.\n",
    "- Execute the statement and `fetchall()` the records.\n",
    "- Print the `state` and `population` change for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0397c6-c890-4099-9507-396eea644f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texas:40137\n",
      "California:35406\n",
      "Florida:21954\n",
      "Arizona:14377\n",
      "Georgia:13357\n"
     ]
    }
   ],
   "source": [
    "# Build query to return state names by population difference from 2008 to 2000: stmt\n",
    "stmt = select([census.columns.state, \n",
    "               (census.columns.pop2008 - \n",
    "                census.columns.pop2000).label('pop_change')])\n",
    "\n",
    "# Append group by for the state: stmt_grouped\n",
    "stmt_grouped = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Append order by for pop_change descendingly: stmt_ordered'\n",
    "stmt_ordered = stmt_grouped.order_by(desc('pop_change'))\n",
    "\n",
    "# Return only 5 results: stmt_top5\n",
    "stmt_top5 = stmt_ordered.limit(5)\n",
    "\n",
    "# Use connection to execute stmt_top5 and fetch all results\n",
    "results = connection.execute(stmt_top5).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}:{}'.format(result.state, result.pop_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60fc02-d1ac-49b0-902f-cdbe663987b3",
   "metadata": {},
   "source": [
    "## Determining the overall percentage of women\n",
    "It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the `case()` expression to operate on data that meets specific criteria while not affecting the query as a whole. The `case()` expression accepts a list of conditions to match and the column to return if the condition matches, followed by an `else_` if none of the conditions match. We can wrap this entire expression in any function or math operation we like.\n",
    "\n",
    "Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the `cast()` function to convert an expression to a particular type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f46d95-050e-443d-a6af-38ad17101cf6",
   "metadata": {},
   "source": [
    "- Import `case`, `cast`, and `Float` from `sqlalchemy`.\n",
    "- Build an expression `female_pop2000` to calculate female population in 2000. To achieve this:\n",
    "    - Use `case()` inside `func.sum()`.\n",
    "    - The first argument of `case()` is a list containing a tuple of\n",
    "        1. A boolean checking that `census.columns.sex` is equal to `'F'`.\n",
    "        2. The column `census.columns.pop2000`.\n",
    "    - The second argument is the `else_` condition, which should be set to 0.\n",
    "- Calculate the total population in 2000 and use `cast()` to convert it to `Float`.\n",
    "- Build a query to calculate the percentage of women in 2000. To do this, divide `female_pop2000` by `total_pop2000` and multiply by `100`.\n",
    "- Execute the query and print `percent_female`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052b64b3-d5ca-4e23-b54a-f40e8d8bb0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.09467432293413\n"
     ]
    }
   ],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build an expression to calculate female population in 2000\n",
    "female_pop2000 = func.sum(\n",
    "                    case([\n",
    "                        (census.columns.sex == 'F', census.columns.pop2000)\n",
    "                    ], else_=0))\n",
    "\n",
    "# Cast an expression to calculate total population in 2000 to Float\n",
    "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
    "\n",
    "# Build a query to calculate the percentage of women in 2000: stmt\n",
    "stmt = select([female_pop2000 / total_pop2000 * 100])\n",
    "\n",
    "# Execute the query and store the scalar result: percent_female\n",
    "percent_female = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the percentage\n",
    "print(percent_female)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f1580-da9e-4106-a687-66fb7d0afc9c",
   "metadata": {},
   "source": [
    "*It looks like there were slightly more women than men in the US population in 2000.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717a7c7-2e2c-42c6-b981-e4b74d210163",
   "metadata": {},
   "source": [
    "---\n",
    "## SQL relationships\n",
    "Tables can be related to one another via columns that act as a bridge between the tables.\n",
    "\n",
    "### Relationships\n",
    "We use relationships to avoid duplicating data. For example, an employee table might be related to a location table so that we can know which location an employee works at without the need to copy the same location data in every employee's record. Relationships allow us to change the data in one place. Back to our employee to location example, if that location moves to a new building, we'd be able to update the address once in the location table, and every employee related to that location would show the new address. Another way that we might use relationships is to store additional details that we don't need to use as often. These relationships might be predefined in the table.\n",
    "\n",
    "### Relationships\n",
    "- `Census`\n",
    "\n",
    "state | sex | age | pop2000 | pop2008\n",
    ":---|:---|:---|:---|:---\n",
    "New York | F | 0 | 120335 | 122194\n",
    "New York | F | 1 | 118219 | 119661\n",
    "New York | F | 2 | 119577 | 116413\n",
    "\n",
    "- `State_Fact`\n",
    "name | abbreviation | type\n",
    ":---|:---|:---\n",
    "New York | NY | state\n",
    "Washington DC | DC | capitol\n",
    "Washington | WA | state\n",
    "\n",
    "In our census data, we have a `census` table and a `state_fact` table that are related by the state name which is found in the state column of the census table and name column of the `state_fact` table. Let's use this predefined relationship to get the state abbreviation from the `state_fact` table instead of the name and the population in 2008 for that same record from the census table. This is called a join.\n",
    "\n",
    "### Automatic joins\n",
    "We build our statement with the column from each table that we desire. Then we can execute the query and print the results. Those results now show each record with the state abbreviation instead of the state name. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9f9ca-8b5d-4f61-934e-226a4d109bec",
   "metadata": {},
   "source": [
    "```python\n",
    "stmt = select([census.columns.pop2008,\n",
    "              state_fact.columns.abbreviation])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "[(95012, u'IL'), (95012, u'NJ'), (95012, u'ND'), (95012, u'OR'), ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30743d99-8350-4373-ae87-7d8cf0e2ffcd",
   "metadata": {},
   "source": [
    "SQLAlchemy automatically adds the right join clause because it is predefined in the database.\n",
    "\n",
    "### Join\n",
    "We can use a join clause to add a relationship that isn't necessarily predefined in a query. The join clause takes a related table and an expression that details the relationship. If the relation is predefined in the table, we don't need that expression. The join clause should be placed right after the select statement and prior to any where, `order_by` or `group_by` clauses. When we want to build queries that do not select a column from each table but use both tables in other clauses, we have to tell SQLAlchemy what to tables to use in the query.\n",
    "\n",
    "### select_from()\n",
    "The `select_from` method of the select statement allows us to do that, and a join clause is passed as the argument to `select_from`.\n",
    "\n",
    "### select_from() example\n",
    "In this example, we want to determine the total population in 2000 that was within the 10th Circuit Court jurisdiction. We use our select statement to sum the `pop2000` column from the census table, then we append the `select_from` method to include the census table joined with the `state_fact` table. Next, we use a where clause to find only the records where the `circuit_court` column from the `state_fact` table is `10`. After executing the statement, we can print our result.\n",
    "\n",
    "```python\n",
    "stmt = select([func.sum(census.columns.pop2000)])\n",
    "stmt = stmt.select_from(census.join(state_fact))\n",
    "stmt = stmt.where(state_fact.columns.circuit_court == '10')\n",
    "result = connection.execute(stmt).scalar()\n",
    "print(result)\n",
    "```\n",
    "```\n",
    "\n",
    "14945252\n",
    "```\n",
    "\n",
    "### Joining tables without predefined relationship\n",
    "So far, we have been using the join statement with a relationship already existing in the database. However, often as a data scientist, we will get tables that have related data, but are not setup with a relationship. To join tables we can give the join clause a Boolean expression that explains how the tables are related. This is the same type of Boolean expression we would use in a `where` clause. This will only join rows from each table that can be related between the two columns. It also doesn't work if the columns are different types.\n",
    "\n",
    "### select_from() example\n",
    "Imagine that we want to determine the total population in 2008 that belongs to the East South Central division of the census; the population and location live in different tables; however, this time I have removed the defined relationship between the `census` and `state_fact` tables so we can practice working with tables in that manner. \n",
    "\n",
    "We begin by selecting the sum of the `pop2000` column from the census table. Next we append a `select_from` to include the join clause. This time in the join clause we specify the table and a condition that matches rows based on the state column of the census table and the name column of the `state_fact` table. Finally, we add a where clause to find the records where the `census_division_name` is `'East South Central'` in the `state_fact` table. Then we execute and print the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "010fb7e9-0c18-4761-af13-3ef3b8255086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16982311\n"
     ]
    }
   ],
   "source": [
    "stmt = select([func.sum(census.columns.pop2000)])\n",
    "stmt = stmt.select_from(\n",
    "                    census.join(state_fact, census.columns.state ==\n",
    "                                state_fact.columns.name))\n",
    "stmt = stmt.where(\n",
    "                state_fact.columns.census_division_name ==\n",
    "                'East South Central')\n",
    "result = connection.execute(stmt).scalar()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7134add-21e8-4b76-be8c-9f432074788d",
   "metadata": {},
   "source": [
    "## Automatic joins with an established relationship\n",
    "If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. Recall the following query:\n",
    "```python\n",
    "stmt = select([census.columns.pop2008, \n",
    "               state_fact.columns.abbreviation])\n",
    "```\n",
    "In order to join the `census` and `state_fact` tables and select the `pop2008` column from the first and the `abbreviation` column from the second. In this case, the `census` and `state_fact` tables had a pre-defined relationship: the `state` column of the former corresponded to the `name` column of the latter.\n",
    "\n",
    "In this exercise, you'll use the same predefined relationship to select the `pop2000` and `abbreviation` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816a296-358f-469f-aa36-b4c5ab1eee81",
   "metadata": {},
   "source": [
    "- Build a statement to join the `census` and `state_fact` tables and select the **`pop2000`** column from the first and the `abbreviation` column from the second.\n",
    "- Execute the statement to get the first result and save it as `result`.\n",
    "- Print the key and value for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48583b68-e3d4-4e67-b5bd-2b96b1de20f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop2000 89600\n",
      "abbreviation IL\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to join census and state_fact tables: stmt\n",
    "stmt = select([census.columns.pop2000, state_fact.columns.abbreviation])\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1666b877-f246-4e30-9cde-0b544063c014",
   "metadata": {},
   "source": [
    "## Joins\n",
    "If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the `.join()` method on a table to join it with another table and get extra data related to our query. The `.join()` takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the `.select_from()` method on the select statement to wrap the join clause. For example, in the previous exercise the following code was executed to join the `census` table to the `state_fact` table such that the `state` column of the `census` table corresponded to the `name` column of the `state_fact` table.\n",
    "\n",
    "```python\n",
    "stmt = stmt.select_from(\n",
    "    census.join(\n",
    "        state_fact, census.columns.state == \n",
    "        state_fact.columns.name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c5512-0866-44a6-8cf2-f4202a4535e4",
   "metadata": {},
   "source": [
    "- Build a statement to select ALL the columns from the `census` and `state_fact` tables. To select ALL the columns from two tables `employees` and `sales`, for example, you would use `stmt = select([employees, sales])`.\n",
    "- Append a `select_from` to `stmt` to join the `census` table to the `state_fact` table by the `state` column in `census` and the `name` column in the `state_fact` table.\n",
    "- Execute the statement to get the first result and save it as `result`. \n",
    "- Print the key and value for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6c6072a-92dc-4b38-93a3-e467cdf84a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state Illinois\n",
      "sex M\n",
      "age 0\n",
      "pop2000 89600\n",
      "pop2008 95012\n",
      "id 13\n",
      "name Illinois\n",
      "abbreviation IL\n",
      "country USA\n",
      "type state\n",
      "sort 10\n",
      "status current\n",
      "occupied occupied\n",
      "notes \n",
      "fips_state 17\n",
      "assoc_press Ill.\n",
      "standard_federal_region V\n",
      "census_region 2\n",
      "census_region_name Midwest\n",
      "census_division 3\n",
      "census_division_name East North Central\n",
      "circuit_court 7\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to select the census and state_fact tables: stmt\n",
    "stmt = select([census, state_fact])\n",
    "\n",
    "# Add a select_from clause that wraps a join for the census and state_fact\n",
    "# tables where the census state column and state_fact name column match\n",
    "stmt_join = stmt.select_from(\n",
    "        census.join(state_fact, \n",
    "                    census.columns.state ==\n",
    "                    state_fact.columns.name))\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt_join).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0198f-7635-4bc2-bb79-f9cdc8f482a8",
   "metadata": {},
   "source": [
    "## More practice with joins\n",
    "You can use the same select statement you built in the last exercise, however, let's add a twist and only return a few columns and use the other table in a `group_by()` clause."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24e4cb-df94-4d4a-8960-365e2a35b521",
   "metadata": {},
   "source": [
    "- Build a statement to select:\n",
    "    - The `state` column from the `census` table.\n",
    "    - The sum of the `pop2008` column from the `census` table.\n",
    "    - The `census_division_name` column from the `state_fact` table.\n",
    "- Append a `.select_from()` to `stmt` in order to join the `census` and `state_fact tables` by the `state` and `name` columns.\n",
    "- Group the statement by the `name` column of the `state_fact table`.\n",
    "- Execute the statement `stmt_grouped` to get all the records and save it as `results`.\n",
    "- Loop over the results object and print each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414cc1fb-122c-4853-a802-ebbd9f5612b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Alabama', 4649367, 'East South Central')\n",
      "('Alaska', 664546, 'Pacific')\n",
      "('Arizona', 6480767, 'Mountain')\n",
      "('Arkansas', 2848432, 'West South Central')\n",
      "('California', 36609002, 'Pacific')\n",
      "('Colorado', 4912947, 'Mountain')\n",
      "('Connecticut', 3493783, 'New England')\n",
      "('Delaware', 869221, 'South Atlantic')\n",
      "('Florida', 18257662, 'South Atlantic')\n",
      "('Georgia', 9622508, 'South Atlantic')\n",
      "('Hawaii', 1250676, 'Pacific')\n",
      "('Idaho', 1518914, 'Mountain')\n",
      "('Illinois', 12867077, 'East North Central')\n",
      "('Indiana', 6373299, 'East North Central')\n",
      "('Iowa', 3000490, 'West North Central')\n",
      "('Kansas', 2782245, 'West North Central')\n",
      "('Kentucky', 4254964, 'East South Central')\n",
      "('Louisiana', 4395797, 'West South Central')\n",
      "('Maine', 1312972, 'New England')\n",
      "('Maryland', 5604174, 'South Atlantic')\n",
      "('Massachusetts', 6492024, 'New England')\n",
      "('Michigan', 9998854, 'East North Central')\n",
      "('Minnesota', 5215815, 'West North Central')\n",
      "('Mississippi', 2922355, 'East South Central')\n",
      "('Missouri', 5891974, 'West North Central')\n",
      "('Montana', 963802, 'Mountain')\n",
      "('Nebraska', 1776757, 'West North Central')\n",
      "('Nevada', 2579387, 'Mountain')\n",
      "('New Hampshire', 1314533, 'New England')\n",
      "('New Jersey', 8670204, 'Mid-Atlantic')\n",
      "('New Mexico', 1974993, 'Mountain')\n",
      "('New York', 19465159, 'Mid-Atlantic')\n",
      "('North Carolina', 9121606, 'South Atlantic')\n",
      "('North Dakota', 634282, 'West North Central')\n",
      "('Ohio', 11476782, 'East North Central')\n",
      "('Oklahoma', 3620620, 'West South Central')\n",
      "('Oregon', 3786824, 'Pacific')\n",
      "('Pennsylvania', 12440129, 'Mid-Atlantic')\n",
      "('Rhode Island', 1046535, 'New England')\n",
      "('South Carolina', 4438870, 'South Atlantic')\n",
      "('South Dakota', 800997, 'West North Central')\n",
      "('Tennessee', 6202407, 'East South Central')\n",
      "('Texas', 24214127, 'West South Central')\n",
      "('Utah', 2730919, 'Mountain')\n",
      "('Vermont', 620602, 'New England')\n",
      "('Virginia', 7648902, 'South Atlantic')\n",
      "('Washington', 6502019, 'Pacific')\n",
      "('West Virginia', 1812879, 'South Atlantic')\n",
      "('Wisconsin', 5625013, 'East North Central')\n",
      "('Wyoming', 529490, 'Mountain')\n"
     ]
    }
   ],
   "source": [
    "# Build a statement to select the state, sum of 2008 population and census\n",
    "# division name: stmt\n",
    "stmt = select([\n",
    "    census.columns.state,\n",
    "    func.sum(census.columns.pop2008),\n",
    "    state_fact.columns.census_division_name\n",
    "])\n",
    "\n",
    "# Append select_from to join the census and state_fact tables by the census state and state_fact name columns\n",
    "stmt_joined = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name)\n",
    ")\n",
    "\n",
    "# Append a group by for the state_fact name column\n",
    "stmt_grouped = stmt_joined.group_by(state_fact.columns.name)\n",
    "\n",
    "# Execute the statement and get the results: results\n",
    "results = connection.execute(stmt_grouped).fetchall()\n",
    "\n",
    "# Loop over the results object and print each record.\n",
    "for record in results:\n",
    "    print(record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85da26f-3b9d-43b4-a80a-769c936c8333",
   "metadata": {},
   "source": [
    "## Working with hierarchical tables\n",
    "In addition to tables that join with other tables, there are also tables that join with themselves.\n",
    "\n",
    "### Hierarchical tables\n",
    "We call these tables self-referential or hierarchical tables. These are commonly used to store organizational charts, geographic data, networks and relationship graphs.\n",
    "\n",
    "### Hierarchical tables - example\n",
    "- `Employees`\n",
    "\n",
    "id | name | job | manager\n",
    ":---|:---|:---|:---|:---\n",
    "1 | Johnson | Admin | 6\n",
    "2 | Harding | Manager | 9\n",
    "3 | Taft | Sales I | 2\n",
    "4 | Hoover | Sales I | 2\n",
    "\n",
    "Here we have an `employees` table, which, in addition to having the employee's name and position, also contains an column for their manager. That manager is also an employee and has a record in that table. The table has an undefined relationship between the id column and the manager column.\n",
    "\n",
    "### Hierarchical tables - alias()\n",
    "In order to use this relationship in a query, we need a way to refer to this table by another name. The `alias` method allows us to do just that by creating a way to refer to the same table with two unique names.\n",
    "\n",
    "### Querying hierarchical data\n",
    "Let's get a list of managers and the employees that report to them. To join the employees table using the relationship, we start by using the `alias` method on the `employees` table and storing the alias as managers. Now we can use both the name managers and employees to refer to the table. Now we are ready to build our query. We start by selecting the `name` column from the `managers` alias and labeling that column as manager. Next we select the `name` column from the `employees` table and label it `employee`. Now we use the select_from method to wrap an explicit join from the `employees` table to the managers alias. We use the `id` column from the managers alias with the `manager` column of the employees table to form the join condition. Next, we order by the managers name. Finally, we execute the statement and review the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f62064d-6829-4a6a-a7c3-070ba3c9d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Table, MetaData, select\n",
    "engine_e = create_engine('sqlite:///employees.sqlite')\n",
    "connection = engine_e.connect()\n",
    "metadata = MetaData()\n",
    "employees = Table('employees', metadata, autoload=True, autoload_with=engine_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5da97e0-c9e9-41b4-a52b-72fabaf2537c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table('employees', MetaData(bind=None), Column('id', INTEGER(), table=<employees>, primary_key=True, nullable=False), Column('name', VARCHAR(length=20), table=<employees>), Column('job', VARCHAR(length=20), table=<employees>), Column('mgr', INTEGER(), table=<employees>), Column('hiredate', DATETIME(), table=<employees>), Column('sal', NUMERIC(precision=7, scale=2), table=<employees>), Column('comm', NUMERIC(precision=7, scale=2), table=<employees>), Column('dept', INTEGER(), table=<employees>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "print(repr(employees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18e0355b-2792-4558-9205-9ca1f3e83930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'name', 'job', 'mgr', 'hiredate', 'sal', 'comm', 'dept']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees.columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36b346c1-75af-4e82-96d0-23386732333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FILLMORE', 'GRANT')\n",
      "('FILLMORE', 'ADAMS')\n",
      "('FILLMORE', 'MONROE')\n",
      "('GARFIELD', 'JOHNSON')\n",
      "('GARFIELD', 'LINCOLN')\n",
      "('GARFIELD', 'POLK')\n",
      "('GARFIELD', 'WASHINGTON')\n",
      "('HARDING', 'TAFT')\n",
      "('HARDING', 'HOOVER')\n",
      "('JACKSON', 'HARDING')\n",
      "('JACKSON', 'GARFIELD')\n",
      "('JACKSON', 'FILLMORE')\n",
      "('JACKSON', 'ROOSEVELT')\n"
     ]
    }
   ],
   "source": [
    "managers = employees.alias()\n",
    "stmt = select(\n",
    "        [managers.columns.name.label('manager'),\n",
    "         employees.columns.name.label('employee')])\n",
    "stmt = stmt.select_from(employees.join(\n",
    "                managers, managers.columns.id ==\n",
    "                employees.columns.mgr))\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "result_e = connection.execute(stmt).fetchall()\n",
    "\n",
    "for result in result_e:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af023a-8bec-4ab3-a5b4-22f180f8736a",
   "metadata": {},
   "source": [
    "For example, Taft's supervisor here is Harding.\n",
    "\n",
    "### group_by and func\n",
    "Hierarchical tables can get tricky when performing `group_by`s or using functions. It's important to think of it as if it were two different tables. You should focus on having the table in the `group_by` and the alias in the function or vice versa. It's super important to make sure you are using both the alias and the table in the query when using the join otherwise you could cause the query to error or use a lot of resources.\n",
    "\n",
    "### Querying hierarchical data\n",
    "To practice this let's pretend that we are making next years budgets and we need to know how much salary to allocate for each managers employees. We start by making the `managers` alias of the `employees` table. Then we begin building the select statement, we select the managers name and then sum all the employees salaries. Next, we use the same explicit join from the previous example in the `select_from`. Next, we group by the managers name and finally we execute the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c37d5201-bed2-4a8e-8153-e1576faaa7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FILLMORE', Decimal('96000.00'))\n",
      "('GARFIELD', Decimal('83500.00'))\n",
      "('HARDING', Decimal('52000.00'))\n",
      "('JACKSON', Decimal('197000.00'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sj501\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\sqltypes.py:659: SAWarning: Dialect sqlite+pysqlite does *not* support Decimal objects natively, and SQLAlchemy must convert from floating point - rounding errors and other issues may occur. Please consider storing Decimal numbers as strings or integers on this platform for lossless storage.\n",
      "  util.warn(\n"
     ]
    }
   ],
   "source": [
    "managers = employees.alias()\n",
    "stmt = select([managers.columns.name,\n",
    "              func.sum(employees.columns.sal)])\n",
    "stmt = stmt.select_from(employees.join(\n",
    "                managers, managers.columns.id ==\n",
    "                employees.columns.mgr))\n",
    "stmt = stmt.group_by(managers.columns.name)\n",
    "result_e = connection.execute(stmt).fetchall()\n",
    "\n",
    "for result in result_e:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a318955-c0c4-41ac-94f8-b85bb52753a5",
   "metadata": {},
   "source": [
    "Notice that we applied the function to the `employees` table and grouped by the `managers` alias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9533b1a-9617-4026-9848-48d3a8b60db4",
   "metadata": {},
   "source": [
    "## Using alias to handle same table joined queries\n",
    "Often, you'll have tables that contain hierarchical data, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The `.alias()` method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition.\n",
    "\n",
    "Here, you'll use the `.alias()` method to build a query to join the `employees` table against itself to determine to whom everyone reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689dbb8c-510f-4a67-80fd-d42655fb3187",
   "metadata": {},
   "source": [
    "## Using alias to handle same table joined queries\n",
    "Often, you'll have tables that contain hierarchical data, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The `.alias()` method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition.\n",
    "\n",
    "Here, you'll use the `.alias()` method to build a query to join the `employees` table against itself to determine to whom everyone reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b3b647-5b65-442d-9c9a-485dacbc045c",
   "metadata": {},
   "source": [
    "- Save an alias of the `employees` table as `managers`. To do so, apply the method `.alias()` to `employees`.\n",
    "- Build a query to select the employee's `name` and their manager's `name`. Use label to `label` the `name` column of `employees` as `'employee'`.\n",
    "- Append a where clause to `stmt` to match where the `id` column of the `managers` table corresponds to the `mgr` column of the `employees` table.\n",
    "- Order the statement by the `name` column of the `managers` table.\n",
    "- Execute the statement and store all the results. Pprint the names of the managers and all their employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1954c039-e2c7-434d-8d55-135721e17ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FILLMORE', 'GRANT')\n",
      "('FILLMORE', 'ADAMS')\n",
      "('FILLMORE', 'MONROE')\n",
      "('GARFIELD', 'JOHNSON')\n",
      "('GARFIELD', 'LINCOLN')\n",
      "('GARFIELD', 'POLK')\n",
      "('GARFIELD', 'WASHINGTON')\n",
      "('HARDING', 'TAFT')\n",
      "('HARDING', 'HOOVER')\n",
      "('JACKSON', 'HARDING')\n",
      "('JACKSON', 'GARFIELD')\n",
      "('JACKSON', 'FILLMORE')\n",
      "('JACKSON', 'ROOSEVELT')\n"
     ]
    }
   ],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select names of managers and their employees: stmt\n",
    "stmt = select(\n",
    "    [managers.columns.name.label('manager'),\n",
    "     employees.columns.name.label('employee')]\n",
    ")\n",
    "\n",
    "# Match managers id with employees mgr: stmt_matched\n",
    "stmt_matched = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Order the statement by the managers name: stmt_ordered\n",
    "stmt_ordered = stmt_matched.order_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt_ordered).fetchall()\n",
    "\n",
    "# Print records\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa374be-378c-450a-9d44-e101ecf5a687",
   "metadata": {},
   "source": [
    "## Leveraging functions and group_bys with hierarchical data\n",
    "It's also common to want to roll up data which is in a hierarchical table. Rolling up data requires making sure you're careful which alias you use to perform the group_bys and which table you use for the function.\n",
    "\n",
    "Here, your job is to get a count of employees for each manager."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9c141-fdcf-4bd3-a4e6-7d6bd36e2bb4",
   "metadata": {},
   "source": [
    "- Save an alias of the `employees` table as `managers`.\n",
    "- Build a query to select the `name` column of the `managers` table and the count of the number of their employees. Use `func.count()` to count the `id `column of the `employees` table.\n",
    "- Using a `.where()` clause, filter the records where the `id` column of the `managers` table and `mgr` column of the `employees` table are equal.\n",
    "- Group the query by the `name` column of the `managers` table.\n",
    "- Execute the statement and store all the results. Print the names of the managers and their employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccc7766e-c456-4fa7-938c-c464c778d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FILLMORE', 3)\n",
      "('GARFIELD', 4)\n",
      "('HARDING', 2)\n",
      "('JACKSON', 4)\n"
     ]
    }
   ],
   "source": [
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select names of managers and counts of their employees: stmt\n",
    "stmt = select([managers.columns.name, func.count(employees.columns.id)])\n",
    "\n",
    "# Append a where clause that ensures the manager id and employee mgr are equal\n",
    "stmt_matched = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Group by Managers Name\n",
    "stmt_grouped = stmt_matched.group_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt_grouped).fetchall()\n",
    "\n",
    "# print manager\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc4f20-7542-46c1-a5af-0c543e7aae45",
   "metadata": {},
   "source": [
    "---\n",
    "## Handling large ResultSets\n",
    "So what do we do when we have really complex queries with large result sets?\n",
    "\n",
    "### Dealing with large ResultSets\n",
    "Dealing with large result sets can be problematic, as we might run out of memory or disk space to store the results. Thankfully, SQLAlchemy has a `fetchmany()` method that allows us to retrieve results so many at a time. It works by passing the number of records we want at once to the `fetchmany()` method and using the method in a loop. When there are no more records, fetchmany will return an empty list. Because the `ResultProxy` does not know when we are done calling fetchmany, we must call the close method on the result proxy when we are done. Let's look at an example.\n",
    "\n",
    "### Fetching many rows\n",
    "I want to count how many results we have for each state; however, we have a HUGE table so I need to work in smaller groups of records with `fetchmany`. We're going to do this in a while loop. Recall that while loops will check to see if a variable or expression is true and if so, it will continue running a loop. When the condition is false, the loop stops executing. In this example, we already have set `more_results` to be True, we also started a `state_count` dictionary to hold the count for each state, and we have already executed the query and stored the results proxy as `results_proxy`. We start the while loop by checking to see if `more_results` is True. Then inside the loop, we fetch 50 records from the results proxy and store that as `partial_results`. We immediately follow that up by checking to see if `partial_results` is an empty list. Remember that is how we know there are no more records to fetch. If it is an empty list, we update `more_results` to be False so we will exit the loop. Next we loop over the `partial_results` and increment the `state_count` for that records state by one. So that will keep running until we get an empty list back from `fetchmany` and exit the while loop. Once we exit the while loop, we close the `results_proxy` so the database and SQLAlchemy know we are done with the large result set.\n",
    "\n",
    "```python\n",
    "while more_results:\n",
    "    partial_results = results_proxy.fetchmanay(50)\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "    for row in partial_results:\n",
    "        state_count[row.state] += 1\n",
    "results_proxy.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4459f-d9a9-4ee6-b0b9-1354a20a8e56",
   "metadata": {},
   "source": [
    "## Working on blocks of records\n",
    "Sometimes you may have the need to work on a large ResultProxy, and you may not have the memory to load all the results at once. To work around that issue, you can get blocks of rows from the ResultProxy by using the `.fetchmany()` method inside a loop. With `.fetchmany()`, give it an argument of the number of records you want. When you reach an empty list, there are no more rows left to fetch, and you have processed all the results of the query. Then you need to use the `.close()` method to close out the connection to the database.\n",
    "\n",
    "You'll now have the chance to practice this on a large ResultProxy called `results_proxy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c105632-91b2-47a5-831b-1578485a3c11",
   "metadata": {},
   "source": [
    "- Use a `while` loop that checks if there are `more_results`.\n",
    "- Inside the loop, apply the method `.fetchmany()` to `results_proxy` to get `50` records at a time and store those records as `partial_results.\n",
    "- After fetching the records, if `partial_results` is an empty list (that is, if it is equal to `[]`), set `more_results` to `False`.\n",
    "- Loop over the `partial_results` and, if `row.state` is a key in the `state_count` dictionary, increment `state_count[row.state]` by 1; otherwise set `state_count[row.state]` to 1.\n",
    "- After the while loop, close the ResultProxy `results_proxy` using `.close()`.\n",
    "- Print `state_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "804d44df-bd06-409b-8d04-6e8cc57a4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Table, MetaData\n",
    "engine = create_engine('sqlite:///census.sqlite')\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "metadata = MetaData()\n",
    "stmt = select([census])\n",
    "results_proxy = connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5651c815-6756-427b-abeb-ba983ad1eadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Illinois': 172, 'New Jersey': 172, 'District of Columbia': 172, 'North Dakota': 172, 'Florida': 172, 'Maryland': 172, 'Idaho': 172, 'Massachusetts': 172, 'Oregon': 172, 'Nevada': 172, 'Michigan': 172, 'Wisconsin': 172, 'Missouri': 172, 'Washington': 172, 'North Carolina': 172, 'Arizona': 172, 'Arkansas': 172, 'Colorado': 172, 'Indiana': 172, 'Pennsylvania': 172, 'Hawaii': 172, 'Kansas': 172, 'Louisiana': 172, 'Alabama': 172, 'Minnesota': 172, 'South Dakota': 172, 'New York': 172, 'California': 172, 'Connecticut': 172, 'Ohio': 172, 'Rhode Island': 172, 'Georgia': 172, 'South Carolina': 172, 'Alaska': 172, 'Delaware': 172, 'Tennessee': 172, 'Vermont': 172, 'Montana': 172, 'Kentucky': 172, 'Utah': 172, 'Nebraska': 172, 'West Virginia': 172, 'Iowa': 172, 'Wyoming': 172, 'Maine': 172, 'New Hampshire': 172, 'Mississippi': 172, 'Oklahoma': 172, 'New Mexico': 172, 'Virginia': 172, 'Texas': 172}\n"
     ]
    }
   ],
   "source": [
    "more_results = True\n",
    "state_count = {}\n",
    "\n",
    "# Start a while loop checking for more results\n",
    "while more_results:\n",
    "    # Fetch the first 50 results from the ResultProxy: partial_results\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "\n",
    "    # if empty list, set more_results to False\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "\n",
    "    # Loop over the fetched records and increment the count for the state\n",
    "    for row in partial_results:\n",
    "        if row.state in state_count:\n",
    "            state_count[row.state] += 1\n",
    "        else:\n",
    "            state_count[row.state] = 1\n",
    "\n",
    "# Close the ResultProxy, and thus the connection\n",
    "results_proxy.close()\n",
    "\n",
    "# Print the count by state\n",
    "print(state_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76dc64-eb6a-4c48-a09a-cc727269e210",
   "metadata": {},
   "source": [
    "*As a data scientist, you'll inevitably come across huge databases, and being able to work on them in blocks is a vital skill.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
